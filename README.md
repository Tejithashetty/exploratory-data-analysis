
# Titanic Dataset - Exploratory Data Analysis (EDA)

## Overview

This repository contains my submission for **Task 5** of the **Data Analyst Internship** program. The task involves performing **Exploratory Data Analysis (EDA)** on the **Titanic Dataset** (or a relevant dataset of your choice) using Python libraries like **Pandas**, **Matplotlib**, and **Seaborn**. The goal is to extract insights, identify patterns, and build familiarity with visual/statistical analysis techniques.

---

## Tools & Libraries Used

- Python
- Pandas
- Matplotlib
- Seaborn
- Jupyter Notebook

---

## Files Included

- `EDA_Titanic.ipynb`: Jupyter Notebook containing the full EDA process.
- `EDA_Titanic_Report.pdf`: PDF version of the notebook with visualizations and observations.
- `train.csv`: Titanic dataset used for the analysis (from [Kaggle](https://www.kaggle.com/c/titanic/data?select=train.csv&utm_source=chatgpt.com)).

---

## Steps Followed in the Analysis

1. **Data Loading and Inspection**
   - Used `.info()`, `.describe()`, and `.head()` to understand structure and summary statistics.

2. **Missing Values & Data Cleaning**
   - Identified and handled missing values appropriately.

3. **Univariate Analysis**
   - Histograms and boxplots to examine individual feature distributions.

4. **Bivariate & Multivariate Analysis**
   - Scatterplots, pairplots, and heatmaps to identify relationships and trends.

5. **Feature Correlation**
   - Explored correlations using `sns.heatmap()` and `sns.pairplot()`.

6. **Observations**
   - Noted insights and patterns for each visual.

7. **Summary of Findings**
   - A concise write-up of key observations and potential implications.
---

## Outcome

Through this task, I gained practical skills in data visualization and statistical analysis. I also strengthened my ability to detect data patterns, anomalies, and correlations â€” foundational skills for any data analyst.

---
